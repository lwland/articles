#### 智能互联网之总体架构设计篇
0. 针对具体业务场景如何选型，架构如何设计折中，架构线上问题如何解决
1. pc-》移动-》物联网 互联网发展的三个阶段 业务越来越复杂，数据量越来越大，请求量越来越大 业务快速迭代和集成
   1. 互动1.0 内容在线 互动方式没变化 一个中心对多点  代表三大门户
   2. 互动2.0 以互动为核心 关注 产品有了自增长的可能 微博 twitter instagram
   3. 互联3.0 群组和朋友圈 关注的一对一变成了网络
2. 互联网架构的演进之路 1->2,3->4->5
   1. 单体架构设计与实践 app->nginx-> tomcat（war包包括所有功能）->mysql（存储）
      1. 优点 容易开发 容易部署 容易测试 容易扩展（部署多个应用）；适用于1、功能不复杂，研发能力不强，2、性能要求苛刻（高频交易系统 经过的层次少）
      2. 缺点 系统耦合度高 技术选型单一 开发效率越来越低
      3. 数据库存储大 拆分（水平分表、垂直分库） 
      4. 架构方向：垂直方向业务拆分（用户、商品、订单 业务纬度）水平方向拆分（网关层、数据层、业务逻辑层、数据访问层、数据存储层功能纬度）
   2. 水平分层架构设计与实践 水平方向分层多个独立进程 各层之间解耦
      1. 分层原则 逻辑服务和数据服务分离 逻辑服务和网关服务分离 网关服务和展示服务分离
      2. 网关层 处理和具体服务无关的 通常使用TCP协议和业务逻辑交互 数据协议采用protobuffer 
         1. 请求鉴权（登陆鉴权）
         2. 数据完整性检查 数据包：定长 header（sessionId,bodyLenth）+ 变长body
         3. 协议转换 JSON-》map ->pd传输
         4. 路由转发
         5. 服务治理 限流 治理 降级
         6. 常用网关框架 zuul(推荐)； spring cloud gateway； tky ；kong；nginx；
      3. 异步消息队列(异步架构中 提升吞吐量)
         1. 任何两层之间加入一个第三层都可以把同步请求变成异步，上游发送请求到MQ，下游发送结果到MQ （提升吞吐量）
         2. 读请求不能用MQ，写请求可以使用MQ
      4. 业务逻辑层 业务逻辑判断，网关服务和业务逻辑分离
         1. 业务黑名单检查
         2. 微信好友删除
         3. 微信不重不漏
      5. 数据访问层 业务和数据服务分离 
         1. crud 支持业务的增删该查
         2. orm mybatis3
         3. Sharding sharding-jdbc（分库分表）数据量很大时候 最难
         4. 屏蔽底层存储细节 Mysql/Mogodb/Redis
      6. 数据存储层
         1. 数据库的阶段 RDBM（mysql oracle 单机时代）-》Nosql（MongoDb，hive，解决分布式但事务性弱）-》NewSql（TiDb不仅具有NoSQL对海量数据的存储管理能力，保持了传统数据库支持ACID和SQL等特性。）
      7. 同步架构（四层）和 异步架构（五层，增加异步消息队列，写请求可以用MQ，读请求不需要MQ；写请求弱一致性；高并发）
         1. 同步架构 APP-》负载均衡（Nginx ）-》网关层（zuul）-》异步消息队列（异步架构中使用）-》业务逻辑层-》数据访问层-》数据存储层
         2. 异步架构 任何两层之间加入MQ都可以变成异步架构，提升吞吐量（写mq是顺序写磁盘、写数据库是随机写磁盘）
            1. 请求路径变长，响应延迟、
      8.  整体架构
         1.  DNS解析
         2.  静态资源获取 请求路径是 CDN，资源没命中-》Nginx，资源没命中-》对象存储（fastDFS ceph）
         3.  动态接口层 NetGw-》Nginx-》网关层-》逻辑层-》数据访问层-》存储层
   3. 面向服务架构设计与实践 SOA仅仅垂直方向拆分
      1. 组件模型 不同功能单元通过良好接口关联 多个独立服务通过ESB（企业服务总线）
      2. 架构模型 垂直业务拆分按照功能模块拆分成独立服务
   4. 微服务架构设计与实践 即有水平拆分又有垂直拆分，2014年拆分
      1. 针对业务垂直拆分 把 每个业务水平拆分 每个微服务单独进程运行、独立部署、可以扩展
      2. APP-》网关层 1个-》业务逻辑层 多个（业务拆分 搜索、房产）-》数据访问层 多个（业务拆分）-》数据库 多个  配置中心Apoll、注册中心
      3. 项目快速迭代 持续交付能力 适用于需求变化频繁  每一层都可以横向扩展性能变高  保证数据最终一致性 同层之间不调用 
      4. 但是微服务中仍然包括通信组件等基础组件耦合在一起
   5. 服务网格架构设计与实践 ServiceMesh 轻量级网络代理，用于处理网络通信的基础设施层 linker 
      1. 基础设施独立出来 服务注册、降级、配置中心等等 下沉为单独一层
      2. slidecar必须和应用程序部署在同机上，slidecar之间通信，应用程序不需要关心通信细节，永远只和本机slidecar交互
3. 性能 
   1. 吞吐量
   2. qps
#### 智能互联网的核心技术
1. 高可用设计手段7*24 任何人、任何时间、任何地点都可用
   1. 高可用 评价纬度
      1. 通常 1个9 90%；2个9 99%； 3个9 99.9%； 4个9；99.99%； 5个9 99.999%  365*24*60*比例  一年内宕机的时间
      2. 科学的 停机时间请求量/总的请求量 有效区分高峰和低峰时期影响
      3. 突发大流量案例 微博突发时间 双11
   2. CAP CP和AP 
   3. 原因：
      1. 硬件 生命周期、硬件故障、网络划分 
      2. 软件 bug、性能极限、软件间相互影响
   4. 手段
      1. 服务冗余 多个服务部署在不同的机柜和机架上
      2. 无状态 保证冗余的服务是完全对等的 有状态宕机恢复不一致；快速扩容缩容
      3. 负载均衡  服务可用保证；流量转移；
      4. 幂等设计
      5. 超时机制 
      6. 异步化设计 简化主流程，核心流程使用同步，非核心流程采用异步
      7. 服务限流和降级熔断
      8. 数据复制（数据库冗余）/缓存（提升响应时间，减小数据库压力）/Sharding
      9. 架构拆分、服务治理
      10. 服务实时监控的手段 （通过日志 接口耗时、异常数量...）
      11. 服务分级 通过服务的重要度
          1.  一级服务 
          2.  二级服务
          3.  三级服务
          4.  四级服务
   5. 案例
      1. 如何无缝切换服务
         1. 网关层具备使用热切换能力下，打开开关拒绝所有的请求，比如8点后所有请求直接返回，等待超时时间过后就可以启用热切换
         2. 网关层无热切换能力 防火墙限制请求只出不进IPtable
2. 高并发设计手段
   1. 目标 提高吞吐量 降低响应延迟 让系统处理合理状态
   2. 手段 调用了多少RPC接口，载入了多少数据 使用了什么算法 非核心流程能否异步化 没有数据依赖并行化
      1. 空间换时间 缓存复用 降低CPU处理时间
      2. 时间换空间 数据大小是瓶颈，比如Http的Gzip压缩响应，App根据版本号获取更新，只下载更新的数据
      3. 系统瓶颈 找到关键流量并分解优化 比如 4w QPS，有5个接口贡献了3.5w
   3. 层次
      1. 架构层面  拆分系统
         1. 分布式系统微服务化
         2. 分库 分表 读写分离 数据分片
         3. 无状态化设计 动态水瓶扩展
         4. 调用链路梳理，热点数据靠近用户
         5. 分布式cache 多级多类缓存
         6. 容量规划
         7. 提前拒绝 保证柔性
      2. 算法层面  
         1. 使用高效的算法
         3. 并发和锁的优化，CAS的lock free 比mutex效率更高
         4. 增量式算法（报表 记录之前计算数据）
         5. 空间是瓶颈时：使用时间换空间 如数据传输使用gzip
         6. 时间是瓶颈时：使用空间换时间 如缓存
         7. TheadLocal 
         8. 并行执行 调用多个rpc接口，接口之间没有依赖的情况下
         9. 异步执行 非核心流程采用异步
      3. 代码层面  
         1. 循环遍历是否高效（调用接口 查询缓存 执行sql等）。调用批量接口组装
         2. 代码避免生成过多的对象和无用对象
         3. ArrayList HashMap 设置的初始是否合理 避免频繁扩容
         4. 数据复用 
         5. 选择合理的数据结构，使用无锁数据结构 比如读多写少的采用copyonwriteArrayList
         6. String/StringBuffer 性能比StringBuild高15倍
         7. 是否正确初始化了数据。有些全局数据 饿汉模式
         8. 使用局部性原理
         9. 合理的使用缓存，热点并不经常数据使用缓存但要注意缓存的命中率，实时性数据考虑更新缓存的一致性
      4. 数据库层
         1. 数据库建表选择小的类型
         2. eunm类型使用tinyint 避免扩展
         3. 避免select* 只要查询的字段 目的是降低 CPU IO 内存 网络消耗 响应时间
         4. 分析查询场景建立合适的索引 分析索引的长度
         5. 字段not null  null字段需要额外的存储
         6. 代码逻辑合理的利用索引
   4. 案例
      1.  秒杀系统
          1.  特点
            1.  大量并发 某一时刻
            2.  有效请求数很少  有效请求和库数量一致
            3.  库存数据一致性要求严格
          2. 思路
              1. 数据分层校验 上层尽可能吧无效请求过滤
              2. 上层可以是不精确的过滤
              3. 层层限流 最后一层做数据一致性校验 扣库存
          3. 设计
              1. HTML JS CSS等静态文件存放在CDN 缓存到用户端
              2. 非实时动态数据 如商品信息、用户是否有秒杀资格、秒杀是否结束等，缓存在靠近用户端
              3. 实时数据，营销数据（红包、折扣）、库存等实时数据存储在缓存过滤一部分数据，如库存为0时不在响应
              4. 最终数据通过数据库事务保证减库
      2. feed系统 
         1. 特点
           1. 读多写少 100读1写
           2. 冷热数据明显 80%的当天数据，20%活跃用户。
           3. 热点效应明显 前几页、大v
           4. 高访问量 没事就刷
           5. 基于写扩散的消息推送渠道 消息标准格式  拆分数据推送
         2. 分级缓存
            1. 读多写少，冷热数据明显， 热数据缓存到用户调用链路近的地方  
            2. 一级缓存存储最热点数据（97%访问前几页数据），二级缓存考虑容量（比如用户的timeline），高热点数据单独缓存，比如大v数据
            3. 基于写扩散消息统一推送渠道
         3. 推送策略 
            1. 推 拆分数据多线程并行推，先推活跃用户，非活跃用户慢慢推
            2. 拉 用户多时采用拉的方式
            3. 消息格式标准化
            4. 统一格式的数据流
         4. 存储内容选型
            1. 微博内容：类型简单、海量访问，Key-value存储/关系数据库 Mysql tiDb
            2. 微博列表：结构化数据、多维度查询 ，关系型数据库 Mysql tiDb
            3. 关系：类型简单、高速访问 持久化Key-value存储 redis pika
            4.  长微博图片视频 对象数据 对象数据库 ceph
            5.  计数 关注数、粉丝数 数据简单访问量大 内存key-value存储 redis

3. 服务无状态化设计
   1. 特点     
      1. 冗余部署的多个模块完全相等
      2. 请求到冗余部署的模块结果完全对等
      3. 模块不存储业务的上下文信息
      4. 仅仅根据每次请求的携带进行数据处理
   2. 目的 快速扩容 缩容
   3. 案例
      1. 用session数据
         1. 登录方式 手机号+验证码/用户名密码
         2. 登录成功 生成用户session/AES(UID+timestamp+校验码)
         3. 存放位置 网关层 离用户近
         4. 如何存放 
            1. 直接存在网关层，网关有状态
               1. 用户session直接存在网关里，单点，网关是有状态的
               2. 每个网关都存储全量的session数据，有状态的，同步困难，形成数据风暴
            2. 存在外部存储 
               1. session 存储在客户端
                  1. 高可用
                  2. 网关无状态化
                  3. session会丢失数据，客户端清数据
               2. session 存储在分布式集群 redis主从
                  1. session高可用
                  2. 网关层无状态化
                  3. 加一层proxy，sharding到不同的主上
                  4. 扩容 session丢失用户重登即可，低峰期做扩容，用户逐渐登录即可生成热点数据。高峰期扩容会造成大量session失效，大量用户重新登录导致服务异常
4. 服务负载均衡设计
   1. 负载均衡系统
      1. 硬件 F5 A10 RadWare
      2. 软件 Lvs(4层)、Nginx(7层)、HAProxy(4层或7层)
      3. 反向代理和正向代理，用户角度来说不知道负载设备存在是反向代理，知道
   2. 算法
      1. Random 随机，设置权重比例
      2. RoundRobin 轮询，按约定的权重轮询
      3. 一致性哈希，相同参数的hash总是发送给同一个
   3. 广义
      1. 完整故障处理和恢复机制
         1. 服务故障自动发现 谁来发现、如何发现、能否发现一切问题
            1. 注册中心（zk，consul)， 每个服务集成zkCli,和zk通过心跳建立链接，服务挂掉时zk 通知网关层
            2. 假死，服务线程挂但zkCli正常，
               1. 网关层根据超时失败比例判断是否熔断
               2. 网关熔断后通知控制中心服务挂
               3. 服务集成一个agent，控制中心通知agent重启服务
               4. agent操作，jstak jdump两次（保存上下文信息，多次用于对比）->kill服务->sleep  6秒（zk心跳3秒一次，两次没有才会认为服务挂掉）->重启
         2. 故障服务自动摘除 服务熔断机制 Hystrix，熔断后重启服务
            1. 物理机 kill process 虚拟机 kill port
         3. 自动重试
         4. 服务恢复自动发现
5. 服务幂等设计 有可能对数据发送改变需要做幂等
   1. 读请求不需要幂等
   2. 写请求有可能需要幂等
6. 分布式锁设计
7. 分布式事务设计
8. 服务降级设计
9.  服务限流/熔断设计
10. 服务灰度发布设计
11. 服务全链路压测设计
12. 千亿真实案例
    